<html>
   <head>
      <style>
         body {
            font-family: "Optima", sans-serif;
            color: #333;
            background-color: #E6E6FA; /* Lavender */
            margin: 0;
            padding: 0;
         }
     
         h1 {
            text-align: center;
            font-size: 2.8em;
            margin: 30px 0 10px 0;
            color: #483D8B; /* Dark Slate Blue */
         }
     
         h2 {
            text-align: center;
            background-color: #D8BFD8; /* Thistle */
            padding: 12px;
            border-radius: 8px;
            margin: 40px auto 20px auto;
            width: 80%;
            color: #483D8B;
            font-size: 1.8em;
            box-shadow: 0 2px 6px rgba(106, 90, 205, 0.2); /* Slate Blue soft shadow */
         }
     
         div {
            text-align: center;
            background-color: white;
            border-radius: 12px;
            margin: 20px auto;
            width: 85%;
         }
     
         p {
            text-align: left;
            font-size: 18px;
            padding: 0 100px;
            line-height: 1.6;
            color: #333;
         }
     
         .image-wrapper {
            display: flex;
            flex-direction: column;
            gap: 20px;
            margin-top: 20px;
            box-shadow: 0px 4px 10px rgba(106, 90, 205, 0.2);
         }
     
         .image-row {
            display: flex;
            gap: 25px;
            justify-content: center;
            flex-wrap: wrap;
         }
     
         .image-container {
            text-align: center;
            max-width: 900px;
         }
     
         img {
            width: 100%;
            height: auto;
            max-width: 500px;
            border-radius: 8px;
            transition: transform 0.3s ease-in-out;
            box-shadow: 0 4px 8px rgba(106, 90, 205, 0.2);
         }
     
         img:hover {
            transform: scale(1.03);
         }
     
         figcaption {
            margin-top: 8px;
            font-size: 16px;
            font-weight: bold;
            color: #483D8B;
         }
     
         .title-container {
            text-align: center;
            background-color: #DDA0DD; /* Plum */
            width: 85%;
            padding: 20px;
            border-radius: 12px;
            margin: 0 auto 30px auto;
            box-shadow: 0px 4px 10px rgba(186, 85, 211, 0.3);
         }
     
         .title-container p {
            margin-top: 5px;
            text-align: center;
            font-size: 18px;
            color: #444;
         }
     
         .styled-table {
            width: 85%;
            margin: 20px auto;
            border-collapse: collapse;
            box-shadow: 0px 4px 10px rgba(106, 90, 205, 0.2);
            background: white;
            text-align: center;
            border-radius: 12px;
            overflow: hidden;
         }
     
         .styled-table th, .styled-table td {
            padding: 15px;
            border: 1px solid #D8BFD8; /* Thistle */
         }
     
         .styled-table th {
            background-color: #E6E6FA;
            font-size: 1.2em;
            color: #6A5ACD;
         }
     
         .styled-table img {
            width: 100px;
            height: auto;
            border-radius: 8px;
            transition: transform 0.3s ease-in-out;
         }
     
         footer {
             text-align: center;
             font-size: 14px;
             color: #999;
             margin: 40px 0;
         }
     </style>
     
   </head>
   <body>
      <div class="title-container">
         <h1>FINAL PROJECT</h1>
         <p>By Flora Cheng and Emily Guo<br>
            16-726 Learning-Based Image Synthesis (Spring 2025)</p>
      </div>
      <h2>Introduction</h2>
      <p>
        In this project, our goal was to create a model such that when given a photo of a face and a desired hairstyle, the model will generate an image of the original input face with the specified hairstyle! This goal was inspired by previous papers that accomplished similar tasks: 
        Learning to Generate and Edit Hairstyles and 
        <a href =https://psh01087.github.io/K-Hairstyle/ >K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification</a>. 
        Our goal was to create a similar model using less computation and quicker training by creating smaller images. 
        <br>
        The dataset used for training was from the 2nd paper, <a href =https://psh01087.github.io/K-Hairstyle/ >K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification</a>, where there are approximately 500k labeled images of 31 types of hairstyles.
        
        planned structure: 
        <div class="image-wrapper"><div class="image-container">
         <img src="structure.png" style="width:900px;"><figcaption>GAN Structure Used</figcaption>
        </div></div>
    </p>

      <h2>Part 1: Naive Model????</h2>
      <p>        
        In the first part of the project, we started from HW3 as a basis
        ...
        this wasn't very good...
        why? 
      </p>
      <div class="image-wrapper"><div class="image-container">
         <img src="naiveLoss.png" style="width:900px;">
        </div>
        <div class="image-container">
         <img src="naiveResults.png" style="width:700px;">
        </div>
      </div>
        <div class="image-row">
            <div class="image-container">
                <img src="outputs/starry_night_tubingen/Reconstructed Image conv 1.png"> 
                <figcaption>Reconstructed image with content loss after 1st Conv2d layer</figcaption>
             </div><div class="image-container">
                <img src="outputs/starry_night_tubingen/Reconstructed Image conv 2.png"> 
                <figcaption>Reconstructed image with content loss after 2nd Conv2d layer</figcaption>
             </div><div class="image-container">
                <img src="outputs/starry_night_tubingen/Reconstructed Image conv 3.png"> 
                <figcaption>Reconstructed image with content loss after 3rd Conv2d layer</figcaption>
             </div><div class="image-container">
                <img src="outputs/starry_night_tubingen/Reconstructed Image conv 4.png"> 
                <figcaption>Reconstructed image with content loss after 4th Conv2d layer</figcaption>
             </div><div class="image-container">
                <img src="outputs/starry_night_tubingen/Reconstructed Image conv 5.png"> 
                <figcaption>Reconstructed image with content loss after 5th Conv2d layer</figcaption>
             </div>
        </div>
     </div>
    <p>
       results look pretty similar, likely becuase of weights on the style + reconstruction loss

       also further checking: the classification not very good. :((
    </p>
    <div class="image-wrapper"><div class="image-container">
        <img src="outputs/starry_night_phipps/Content Image.png"> 
        <figcaption>Content Image that the model is trying to match </figcaption>
     </div>
        <div class="image-row">
            <div class="image-container">
                <img src="outputs/starry_night_phipps/Reconstructed Image 1 5.png"> 
                <figcaption>Reconstructed image 1</figcaption>
             </div><div class="image-container">
                <img src="outputs/starry_night_phipps/Reconstructed Image.png"> 
                <figcaption>Reconstructed image 2</figcaption>
             </div>
        </div>
     </div>
      
      <h2>Part 2: Pretrained model</h2>
      <p>
        In the second part of this project, we tried a pretrained model, maybe it will be better at extracting features!
        changed the loss from L1/L2 to BCE -- idk i think better for image features

        probably in both parts: instert loss graph
        
        I'll run for some results...
      </p>
      <div class="image-wrapper">
        <div class="image-container">
         <img src="pretrainedResults.png" style="width:900px;">
        </div>
      </div>
        <div class="image-row">
            <div class="image-container">
                <img src="outputs/starry_night_tubingen/Synthesized Texture all.png"> 
                <figcaption>Generated style with style loss after every convolution layer </figcaption>
             </div>
             <div class="image-container">
                <img src="outputs/starry_night_tubingen/Synthesized Texture 1 3 5.png"> 
                <figcaption>Generated style with style loss after the 1st, 3rd, and 5th convolution layer </figcaption>
             </div>
             <div class="image-container">
                <img src="outputs/starry_night_tubingen/Synthesized Texture 1.png"> 
                <figcaption>Generated style with style loss after the 1st convolution layer </figcaption>
             </div>
             <div class="image-container">
                <img src="outputs/starry_night_tubingen/Synthesized Texture 5.png"> 
                <figcaption>Generated style with style loss after the 5th convolution layer </figcaption>
             </div>
        </div>
     </div>
     <p>We can see as we use less style layers, we end up with a less detailed texture result, where there's less notable brush stroke and theres larger blotches of colors. And in the cases with just a single layer, it's pretty noisy and isn't a very cohesive layer, where having just style loss in the earlier layers looks like noise with a couple strokes and having the style loss in a later layer results in more details but still a lot of noise.
        To get something with a closer texture to the original style image, I would pick to have style loss after each layer, such that we can guarantee the model's style is very close to the original style image.<br>

        With this optimization, we can see the following results when starting from noise and generating the styles:
    </p>
    <div class="image-wrapper"><div class="image-container">
      <img src="outputs/picasso_dancing/Style Image.png"> 
      <figcaption>Style Image that the model is trying to match </figcaption>
   </div>
      <div class="image-row">
          <div class="image-container">
              <img src="outputs/picasso_dancing/Synthesized Texture 1.png"> 
              <figcaption>Style image 1</figcaption>
           </div><div class="image-container">
              <img src="outputs/picasso_dancing/Synthesized Texture 2.png"> 
              <figcaption>Style image 2</figcaption>
           </div>
      </div>
   </div> 

      <h2>Part 3: CLIP</h2>
      <p>
         Consider the possibilty that maybe training data isn't enought/consistnetn enough for models to pic up features
         ==> use clip, already has embeddings
         ==> updated flow chart: style loss if found w/ clip using cosine loss
        
      </p>
      <div class="image-wrapper">
         <div class="image-container">
          <img src="clipPartialRes2500.png" style="width:900px;">
         </div>
       </div>
        <table class="styled-table">
            <thead>
               <tr>
                  <th>Content \ Style</th>
                  <th><img src="outputs/the_scream_tubingen/Style Image.png" alt="The Scream Style"><br>The Scream</th>
                  <th><img src="outputs/picasso_phipps/Style Image.png" alt="Picasso Style"><br>Picasso</th>
               </tr>
            </thead>
            <tbody>
               <tr>
                  <td><img src="outputs/picasso_tubingen/Content Image.png" alt="Tubingen Content"><br>Tubingen</td>
                  <td><img src="outputs/the_scream_tubingen/Output Image from noise.png" alt="Output Scream Tubingen"></td>
                  <td><img src="outputs/picasso_tubingen/Output Image from noise.png" alt="Output Picasso Tubingen"></td>
               </tr>
               <tr>
                  <td><img src="outputs/picasso_phipps/Content Image.png" alt="Phipps Content"><br>Phipps</td>
                  <td><img src="outputs/the_scream_phipps/Output Image from noise.png" alt="Output Scream Phipps"></td>
                  <td><img src="outputs/picasso_phipps/Output Image from noise.png" alt="Output Picasso Phipps"></td>
               </tr>
            </tbody>
         </table>
        <p>
        Note these images were generated with the input as random noise. However we could also try using the content image as input too. Because we are starting with the content image, we can note below that the content input image result has more accurate results?</p>
        <div class="image-wrapper">
            <div class="image-row">
            <div class="image-container">
                <img src="outputs/picasso_dancing/Style Image.png"> 
                <figcaption>Style image</figcaption>
             </div><div class="image-container">
                <img src="outputs/picasso_dancing/Content Image.png"> 
                <figcaption>Content image</figcaption>
             </div>
        </div>
            <div class="image-row">
                <div class="image-container">
                    <img src="outputs/picasso_dancing/Output Image from noise.png"> 
                    <figcaption>Noise as Input</figcaption>
                 </div><div class="image-container">
                    <img src="outputs/picasso_dancing/Output Image from content image.png"> 
                    <figcaption>Content image as Input</figcaption>
                 </div>
            </div>
         </div> 
        <p>
        Now lets try the style transfer on some of my own images. I used an image taken at a lantern festival for the content and a background I drew a while ago as the style.
      </p>
      <div class="image-wrapper">
        <div class="image-row">
        <div class="image-container">
            <img src="outputs/sunset_lanterns/Style Image.png"> 
            <figcaption>Style image</figcaption>
         </div><div class="image-container">
            <img src="outputs/sunset_lanterns/Content Image.png"> 
            <figcaption>Content image</figcaption>
         </div><div class="image-container">
            <img src="outputs/sunset_lanterns/Output Image from noise.png"> 
            <figcaption>output image</figcaption>
         </div>
    </div>  
</div>  
      <h2>Application</h2>
      <p>
         The final goal, was to be able to take in a face, and output a new hairstyel:

         flowchart: 
         face ==> blurr => model G => transplant face ==> output!
      </p>
      <div class="image-wrapper">
        <div class="image-row">
        <div class="image-container">
            <img src="outputs/picasso_hw2/Style Image.png"> 
            <figcaption>Style image</figcaption>
         </div><div class="image-container">
            <img src="outputs/picasso_hw2/Content Image.png"> 
            <figcaption>Content image</figcaption>
         </div><div class="image-container">
            <img src="outputs/picasso_hw2/Output Image from noise.png"> 
            <figcaption>output image</figcaption>
         </div>
    </div>  
</div>  
<h2>Final Results</h2>
<p>uhhhhhhhhhhh hope</p>
   </body>
</html>
