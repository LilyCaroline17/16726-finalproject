/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
================================================================================
                                      Opts                                      
--------------------------------------------------------------------------------
                             image_size: 128                                    
                                   disc: dc                                     
                                    gen: cycle                                  
                                   iden: pretrained                             
                             g_conv_dim: 32                                     
                             d_conv_dim: 32                                     
                                   norm: instance                               
                              init_type: naive                                  
                            train_iters: 10000                                  
                             batch_size: 16                                     
                            num_workers: 2                                      
                                     lr: 0.0003                                 
                                  beta1: 0.5                                    
                                  beta2: 0.999                                  
                           lambda_cycle: 10                                     
                           lambda_style: 10                                     
                                      X: ..                                     
                                    ext: *.png                                  
                        data_preprocess: vanilla                                
                         checkpoint_dir: checkpoints_stylegan                   
                   iden_checkpoint_dir: checkpoints_pretrained_style_id         
                    sample_dir: output/cyclegan/.._10vanilla_instance_dc_cycle_naive
                               log_step: 10                                     
                           sample_every: 100                                    
                       checkpoint_every: 1000                                   
                                    gpu: 0                                      
================================================================================
Loaded 393345 samples from ../labels
Models moved to GPU.
Loading Style Identifier from checkpoints_pretrained_style_id/style_identifier_iter49600.pkl
No checkpoint found, initializing new models.
                 G                
---------------------------------------
Generator(
  (conv1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (mlp): Sequential(
    (0): Linear(in_features=31, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
  )
  (resnet_block): Sequential(
    (0): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
    (1): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
    (2): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
  )
  (up_conv1): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU()
  )
  (up_conv2): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU()
  )
  (up_conv3): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Tanh()
  )
)
---------------------------------------
                 D                
---------------------------------------
Discriminator(
  (conv1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv4): Sequential(
    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv5): Sequential(
    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))
  )
)
---------------------------------------
                  style_identifier                  
---------------------------------------
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=31, bias=True)
)
---------------------------------------
Iteration [    0/10000] | d_real_loss: 1.0706 | d_fake_loss: 0.1285 | d_total_loss: 1.1991 |  g_loss: 0.1654
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000000.png
Iteration [   10/10000] | d_real_loss: 0.1852 | d_fake_loss: 0.2549 | d_total_loss: 0.4401 |  g_loss: 1.0031
Iteration [   20/10000] | d_real_loss: 0.4024 | d_fake_loss: 0.1532 | d_total_loss: 0.5556 |  g_loss: 0.4394
Iteration [   30/10000] | d_real_loss: 0.2287 | d_fake_loss: 0.2935 | d_total_loss: 0.5221 |  g_loss: 0.4632
Iteration [   40/10000] | d_real_loss: 0.3136 | d_fake_loss: 0.2009 | d_total_loss: 0.5145 |  g_loss: 0.4203
Iteration [   50/10000] | d_real_loss: 0.3610 | d_fake_loss: 0.1800 | d_total_loss: 0.5410 |  g_loss: 0.3780
Iteration [   60/10000] | d_real_loss: 0.1535 | d_fake_loss: 0.3931 | d_total_loss: 0.5466 |  g_loss: 0.5694
Iteration [   70/10000] | d_real_loss: 0.3784 | d_fake_loss: 0.1674 | d_total_loss: 0.5458 |  g_loss: 0.2698
Iteration [   80/10000] | d_real_loss: 0.3017 | d_fake_loss: 0.1721 | d_total_loss: 0.4738 |  g_loss: 0.3401
Iteration [   90/10000] | d_real_loss: 0.2127 | d_fake_loss: 0.2580 | d_total_loss: 0.4707 |  g_loss: 0.3945
Iteration [  100/10000] | d_real_loss: 0.2702 | d_fake_loss: 0.2109 | d_total_loss: 0.4811 |  g_loss: 0.3721
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000100.png
Iteration [  110/10000] | d_real_loss: 0.1871 | d_fake_loss: 0.3001 | d_total_loss: 0.4873 |  g_loss: 0.5270
Iteration [  120/10000] | d_real_loss: 0.2253 | d_fake_loss: 0.2434 | d_total_loss: 0.4687 |  g_loss: 0.3607
Iteration [  130/10000] | d_real_loss: 0.2412 | d_fake_loss: 0.2345 | d_total_loss: 0.4757 |  g_loss: 0.3836
Iteration [  140/10000] | d_real_loss: 0.2471 | d_fake_loss: 0.1976 | d_total_loss: 0.4447 |  g_loss: 0.3080
Iteration [  150/10000] | d_real_loss: 0.1721 | d_fake_loss: 0.2869 | d_total_loss: 0.4590 |  g_loss: 0.5362
Iteration [  160/10000] | d_real_loss: 0.1035 | d_fake_loss: 0.3671 | d_total_loss: 0.4706 |  g_loss: 0.8992
Iteration [  170/10000] | d_real_loss: 0.1773 | d_fake_loss: 0.2253 | d_total_loss: 0.4026 |  g_loss: 0.3580
Iteration [  180/10000] | d_real_loss: 0.5160 | d_fake_loss: 0.0831 | d_total_loss: 0.5991 |  g_loss: 0.1430
Iteration [  190/10000] | d_real_loss: 0.2302 | d_fake_loss: 0.1743 | d_total_loss: 0.4046 |  g_loss: 0.4363
Iteration [  200/10000] | d_real_loss: 0.1683 | d_fake_loss: 0.2512 | d_total_loss: 0.4195 |  g_loss: 0.3916
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000200.png
Iteration [  210/10000] | d_real_loss: 0.1254 | d_fake_loss: 0.3345 | d_total_loss: 0.4599 |  g_loss: 0.6694
Iteration [  220/10000] | d_real_loss: 0.1437 | d_fake_loss: 0.3308 | d_total_loss: 0.4744 |  g_loss: 0.6383
Iteration [  230/10000] | d_real_loss: 0.3607 | d_fake_loss: 0.0693 | d_total_loss: 0.4300 |  g_loss: 0.2335
Iteration [  240/10000] | d_real_loss: 0.1202 | d_fake_loss: 0.2938 | d_total_loss: 0.4139 |  g_loss: 0.8347
Iteration [  250/10000] | d_real_loss: 0.1750 | d_fake_loss: 0.2433 | d_total_loss: 0.4183 |  g_loss: 0.3596
Iteration [  260/10000] | d_real_loss: 0.4128 | d_fake_loss: 0.0606 | d_total_loss: 0.4734 |  g_loss: 0.1451
Iteration [  270/10000] | d_real_loss: 0.2554 | d_fake_loss: 0.1573 | d_total_loss: 0.4127 |  g_loss: 0.3546
Iteration [  280/10000] | d_real_loss: 0.1987 | d_fake_loss: 0.2607 | d_total_loss: 0.4594 |  g_loss: 0.4418
Iteration [  290/10000] | d_real_loss: 0.2496 | d_fake_loss: 0.2290 | d_total_loss: 0.4786 |  g_loss: 0.4461
Iteration [  300/10000] | d_real_loss: 0.2354 | d_fake_loss: 0.2086 | d_total_loss: 0.4439 |  g_loss: 0.4271
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000300.png
Iteration [  310/10000] | d_real_loss: 0.3562 | d_fake_loss: 0.0826 | d_total_loss: 0.4388 |  g_loss: 0.2372
Iteration [  320/10000] | d_real_loss: 0.3941 | d_fake_loss: 0.0890 | d_total_loss: 0.4831 |  g_loss: 0.2009
Iteration [  330/10000] | d_real_loss: 0.1038 | d_fake_loss: 0.4306 | d_total_loss: 0.5344 |  g_loss: 0.6221
Iteration [  340/10000] | d_real_loss: 0.4663 | d_fake_loss: 0.0576 | d_total_loss: 0.5239 |  g_loss: 0.1785
Iteration [  350/10000] | d_real_loss: 0.2299 | d_fake_loss: 0.2007 | d_total_loss: 0.4306 |  g_loss: 0.5025
Iteration [  360/10000] | d_real_loss: 0.1272 | d_fake_loss: 0.3590 | d_total_loss: 0.4862 |  g_loss: 0.7259
Iteration [  370/10000] | d_real_loss: 0.0681 | d_fake_loss: 0.3965 | d_total_loss: 0.4646 |  g_loss: 0.8016
Iteration [  380/10000] | d_real_loss: 0.2371 | d_fake_loss: 0.1124 | d_total_loss: 0.3495 |  g_loss: 0.4316
Iteration [  390/10000] | d_real_loss: 0.3160 | d_fake_loss: 0.0972 | d_total_loss: 0.4132 |  g_loss: 0.3489
Iteration [  400/10000] | d_real_loss: 0.3818 | d_fake_loss: 0.1838 | d_total_loss: 0.5656 |  g_loss: 0.3442
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000400.png
Iteration [  410/10000] | d_real_loss: 0.3864 | d_fake_loss: 0.0978 | d_total_loss: 0.4841 |  g_loss: 0.2708
Iteration [  420/10000] | d_real_loss: 0.1315 | d_fake_loss: 0.3167 | d_total_loss: 0.4482 |  g_loss: 0.6094
Iteration [  430/10000] | d_real_loss: 0.0813 | d_fake_loss: 0.4741 | d_total_loss: 0.5555 |  g_loss: 0.9434
Iteration [  440/10000] | d_real_loss: 0.2413 | d_fake_loss: 0.1968 | d_total_loss: 0.4381 |  g_loss: 0.4102
Iteration [  450/10000] | d_real_loss: 0.3314 | d_fake_loss: 0.1881 | d_total_loss: 0.5195 |  g_loss: 0.2944
Iteration [  460/10000] | d_real_loss: 0.1869 | d_fake_loss: 0.2405 | d_total_loss: 0.4274 |  g_loss: 0.5875
Iteration [  470/10000] | d_real_loss: 0.1543 | d_fake_loss: 0.2633 | d_total_loss: 0.4177 |  g_loss: 0.6181
Iteration [  480/10000] | d_real_loss: 0.2410 | d_fake_loss: 0.1798 | d_total_loss: 0.4208 |  g_loss: 0.3251
Iteration [  490/10000] | d_real_loss: 0.1736 | d_fake_loss: 0.2417 | d_total_loss: 0.4153 |  g_loss: 0.5932
Iteration [  500/10000] | d_real_loss: 0.3559 | d_fake_loss: 0.1001 | d_total_loss: 0.4560 |  g_loss: 0.2443
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000500.png
Iteration [  510/10000] | d_real_loss: 0.3400 | d_fake_loss: 0.1184 | d_total_loss: 0.4584 |  g_loss: 0.2598
Iteration [  520/10000] | d_real_loss: 0.4025 | d_fake_loss: 0.1033 | d_total_loss: 0.5058 |  g_loss: 0.3061
Iteration [  530/10000] | d_real_loss: 0.2837 | d_fake_loss: 0.2068 | d_total_loss: 0.4905 |  g_loss: 0.3788
Iteration [  540/10000] | d_real_loss: 0.3724 | d_fake_loss: 0.1211 | d_total_loss: 0.4934 |  g_loss: 0.3908
Iteration [  550/10000] | d_real_loss: 0.3558 | d_fake_loss: 0.0944 | d_total_loss: 0.4502 |  g_loss: 0.2950
Iteration [  560/10000] | d_real_loss: 0.3798 | d_fake_loss: 0.0847 | d_total_loss: 0.4645 |  g_loss: 0.1630
Iteration [  570/10000] | d_real_loss: 0.3080 | d_fake_loss: 0.1262 | d_total_loss: 0.4343 |  g_loss: 0.3019
Iteration [  580/10000] | d_real_loss: 0.2637 | d_fake_loss: 0.1597 | d_total_loss: 0.4234 |  g_loss: 0.3050
Iteration [  590/10000] | d_real_loss: 0.2916 | d_fake_loss: 0.1247 | d_total_loss: 0.4163 |  g_loss: 0.3082
Iteration [  600/10000] | d_real_loss: 0.2388 | d_fake_loss: 0.2050 | d_total_loss: 0.4438 |  g_loss: 0.4108
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000600.png
Iteration [  610/10000] | d_real_loss: 0.1946 | d_fake_loss: 0.1771 | d_total_loss: 0.3717 |  g_loss: 0.4769
Iteration [  620/10000] | d_real_loss: 0.2290 | d_fake_loss: 0.1593 | d_total_loss: 0.3883 |  g_loss: 0.2994
Iteration [  630/10000] | d_real_loss: 0.0425 | d_fake_loss: 0.6642 | d_total_loss: 0.7067 |  g_loss: 1.1380
Iteration [  640/10000] | d_real_loss: 0.2306 | d_fake_loss: 0.1773 | d_total_loss: 0.4079 |  g_loss: 0.4443
Iteration [  650/10000] | d_real_loss: 0.3160 | d_fake_loss: 0.1170 | d_total_loss: 0.4330 |  g_loss: 0.2081
Iteration [  660/10000] | d_real_loss: 0.1881 | d_fake_loss: 0.1946 | d_total_loss: 0.3827 |  g_loss: 0.5253
Iteration [  670/10000] | d_real_loss: 0.0680 | d_fake_loss: 0.3388 | d_total_loss: 0.4069 |  g_loss: 0.6686
Iteration [  680/10000] | d_real_loss: 0.1325 | d_fake_loss: 0.2772 | d_total_loss: 0.4097 |  g_loss: 0.5766
Iteration [  690/10000] | d_real_loss: 0.3365 | d_fake_loss: 0.1943 | d_total_loss: 0.5308 |  g_loss: 0.3913
Iteration [  700/10000] | d_real_loss: 0.1369 | d_fake_loss: 0.2405 | d_total_loss: 0.3775 |  g_loss: 0.4395
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000700.png
Iteration [  710/10000] | d_real_loss: 0.1937 | d_fake_loss: 0.1763 | d_total_loss: 0.3700 |  g_loss: 0.4797
Iteration [  720/10000] | d_real_loss: 0.3086 | d_fake_loss: 0.0919 | d_total_loss: 0.4004 |  g_loss: 0.3539
Iteration [  730/10000] | d_real_loss: 0.2543 | d_fake_loss: 0.1398 | d_total_loss: 0.3941 |  g_loss: 0.3168
Iteration [  740/10000] | d_real_loss: 0.3072 | d_fake_loss: 0.1165 | d_total_loss: 0.4238 |  g_loss: 0.2788
Iteration [  750/10000] | d_real_loss: 0.3118 | d_fake_loss: 0.1623 | d_total_loss: 0.4741 |  g_loss: 0.3835
Iteration [  760/10000] | d_real_loss: 0.1543 | d_fake_loss: 0.2448 | d_total_loss: 0.3991 |  g_loss: 0.5248
Iteration [  770/10000] | d_real_loss: 0.3136 | d_fake_loss: 0.1451 | d_total_loss: 0.4587 |  g_loss: 0.3234
Iteration [  780/10000] | d_real_loss: 0.2535 | d_fake_loss: 0.1449 | d_total_loss: 0.3984 |  g_loss: 0.3913
Iteration [  790/10000] | d_real_loss: 0.0999 | d_fake_loss: 0.2904 | d_total_loss: 0.3903 |  g_loss: 0.6726
Iteration [  800/10000] | d_real_loss: 0.4868 | d_fake_loss: 0.0565 | d_total_loss: 0.5433 |  g_loss: 0.2636
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000800.png
Iteration [  810/10000] | d_real_loss: 0.1746 | d_fake_loss: 0.3333 | d_total_loss: 0.5078 |  g_loss: 0.4970
Iteration [  820/10000] | d_real_loss: 0.1207 | d_fake_loss: 0.2814 | d_total_loss: 0.4021 |  g_loss: 0.7877
Iteration [  830/10000] | d_real_loss: 0.1121 | d_fake_loss: 0.3270 | d_total_loss: 0.4391 |  g_loss: 0.7139
Iteration [  840/10000] | d_real_loss: 0.3111 | d_fake_loss: 0.1221 | d_total_loss: 0.4332 |  g_loss: 0.2926
Iteration [  850/10000] | d_real_loss: 0.3140 | d_fake_loss: 0.0969 | d_total_loss: 0.4109 |  g_loss: 0.3620
Iteration [  860/10000] | d_real_loss: 0.4879 | d_fake_loss: 0.0972 | d_total_loss: 0.5851 |  g_loss: 0.1483
Iteration [  870/10000] | d_real_loss: 0.1617 | d_fake_loss: 0.2367 | d_total_loss: 0.3983 |  g_loss: 0.5052
Iteration [  880/10000] | d_real_loss: 0.1383 | d_fake_loss: 0.3344 | d_total_loss: 0.4727 |  g_loss: 0.8225
Iteration [  890/10000] | d_real_loss: 0.2417 | d_fake_loss: 0.1526 | d_total_loss: 0.3943 |  g_loss: 0.3349
Iteration [  900/10000] | d_real_loss: 0.1668 | d_fake_loss: 0.2253 | d_total_loss: 0.3920 |  g_loss: 0.5298
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-000900.png
Iteration [  910/10000] | d_real_loss: 0.2489 | d_fake_loss: 0.1562 | d_total_loss: 0.4051 |  g_loss: 0.3886
Iteration [  920/10000] | d_real_loss: 0.3985 | d_fake_loss: 0.0716 | d_total_loss: 0.4702 |  g_loss: 0.2063
Iteration [  930/10000] | d_real_loss: 0.2515 | d_fake_loss: 0.1482 | d_total_loss: 0.3997 |  g_loss: 0.4049
Iteration [  940/10000] | d_real_loss: 0.2528 | d_fake_loss: 0.1752 | d_total_loss: 0.4281 |  g_loss: 0.3912
Iteration [  950/10000] | d_real_loss: 0.5089 | d_fake_loss: 0.0780 | d_total_loss: 0.5869 |  g_loss: 0.2570
Iteration [  960/10000] | d_real_loss: 0.1304 | d_fake_loss: 0.2231 | d_total_loss: 0.3535 |  g_loss: 0.6677
Iteration [  970/10000] | d_real_loss: 0.1830 | d_fake_loss: 0.2088 | d_total_loss: 0.3917 |  g_loss: 0.4329
Iteration [  980/10000] | d_real_loss: 0.1771 | d_fake_loss: 0.2060 | d_total_loss: 0.3831 |  g_loss: 0.5738
Iteration [  990/10000] | d_real_loss: 0.2474 | d_fake_loss: 0.2302 | d_total_loss: 0.4776 |  g_loss: 0.4680
Iteration [ 1000/10000] | d_real_loss: 0.3308 | d_fake_loss: 0.0791 | d_total_loss: 0.4099 |  g_loss: 0.2521
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001000.png
Iteration [ 1010/10000] | d_real_loss: 0.5363 | d_fake_loss: 0.0594 | d_total_loss: 0.5957 |  g_loss: 0.1759
Iteration [ 1020/10000] | d_real_loss: 0.2988 | d_fake_loss: 0.1347 | d_total_loss: 0.4336 |  g_loss: 0.3952
Iteration [ 1030/10000] | d_real_loss: 0.0947 | d_fake_loss: 0.3139 | d_total_loss: 0.4087 |  g_loss: 0.7595
Iteration [ 1040/10000] | d_real_loss: 0.1325 | d_fake_loss: 0.2814 | d_total_loss: 0.4139 |  g_loss: 0.5520
Iteration [ 1050/10000] | d_real_loss: 0.3125 | d_fake_loss: 0.1208 | d_total_loss: 0.4333 |  g_loss: 0.4109
Iteration [ 1060/10000] | d_real_loss: 0.1523 | d_fake_loss: 0.2748 | d_total_loss: 0.4271 |  g_loss: 0.5330
Iteration [ 1070/10000] | d_real_loss: 0.1380 | d_fake_loss: 0.2606 | d_total_loss: 0.3986 |  g_loss: 0.7524
Iteration [ 1080/10000] | d_real_loss: 0.5872 | d_fake_loss: 0.0604 | d_total_loss: 0.6476 |  g_loss: 0.1816
Iteration [ 1090/10000] | d_real_loss: 0.1891 | d_fake_loss: 0.1745 | d_total_loss: 0.3636 |  g_loss: 0.5717
Iteration [ 1100/10000] | d_real_loss: 0.1545 | d_fake_loss: 0.2968 | d_total_loss: 0.4513 |  g_loss: 0.6779
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001100.png
Iteration [ 1110/10000] | d_real_loss: 0.1750 | d_fake_loss: 0.2781 | d_total_loss: 0.4531 |  g_loss: 0.4329
Iteration [ 1120/10000] | d_real_loss: 0.2795 | d_fake_loss: 0.1405 | d_total_loss: 0.4200 |  g_loss: 0.3230
Iteration [ 1130/10000] | d_real_loss: 0.2037 | d_fake_loss: 0.1495 | d_total_loss: 0.3532 |  g_loss: 0.6035
Iteration [ 1140/10000] | d_real_loss: 0.2492 | d_fake_loss: 0.1483 | d_total_loss: 0.3974 |  g_loss: 0.3633
Iteration [ 1150/10000] | d_real_loss: 0.0870 | d_fake_loss: 0.2657 | d_total_loss: 0.3527 |  g_loss: 0.9215
Iteration [ 1160/10000] | d_real_loss: 0.4124 | d_fake_loss: 0.0978 | d_total_loss: 0.5102 |  g_loss: 0.3442
Iteration [ 1170/10000] | d_real_loss: 0.1830 | d_fake_loss: 0.1857 | d_total_loss: 0.3687 |  g_loss: 0.4912
Iteration [ 1180/10000] | d_real_loss: 0.3643 | d_fake_loss: 0.0696 | d_total_loss: 0.4340 |  g_loss: 0.2142
Iteration [ 1190/10000] | d_real_loss: 0.1459 | d_fake_loss: 0.2975 | d_total_loss: 0.4435 |  g_loss: 0.5999
Iteration [ 1200/10000] | d_real_loss: 0.2616 | d_fake_loss: 0.0969 | d_total_loss: 0.3585 |  g_loss: 0.3869
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001200.png
Iteration [ 1210/10000] | d_real_loss: 0.1221 | d_fake_loss: 0.2853 | d_total_loss: 0.4074 |  g_loss: 0.5912
Iteration [ 1220/10000] | d_real_loss: 0.3451 | d_fake_loss: 0.0801 | d_total_loss: 0.4252 |  g_loss: 0.2788
Iteration [ 1230/10000] | d_real_loss: 0.2055 | d_fake_loss: 0.2050 | d_total_loss: 0.4105 |  g_loss: 0.4111
Iteration [ 1240/10000] | d_real_loss: 0.2617 | d_fake_loss: 0.0784 | d_total_loss: 0.3401 |  g_loss: 0.4018
Iteration [ 1250/10000] | d_real_loss: 0.1288 | d_fake_loss: 0.2923 | d_total_loss: 0.4211 |  g_loss: 0.7073
Iteration [ 1260/10000] | d_real_loss: 0.1130 | d_fake_loss: 0.3062 | d_total_loss: 0.4192 |  g_loss: 0.7685
Iteration [ 1270/10000] | d_real_loss: 0.1504 | d_fake_loss: 0.2503 | d_total_loss: 0.4007 |  g_loss: 0.5540
Iteration [ 1280/10000] | d_real_loss: 0.2142 | d_fake_loss: 0.1717 | d_total_loss: 0.3859 |  g_loss: 0.4742
Iteration [ 1290/10000] | d_real_loss: 0.1037 | d_fake_loss: 0.2838 | d_total_loss: 0.3875 |  g_loss: 0.5973
Iteration [ 1300/10000] | d_real_loss: 0.2698 | d_fake_loss: 0.1110 | d_total_loss: 0.3808 |  g_loss: 0.3151
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001300.png
Iteration [ 1310/10000] | d_real_loss: 0.1749 | d_fake_loss: 0.2177 | d_total_loss: 0.3926 |  g_loss: 0.5366
Iteration [ 1320/10000] | d_real_loss: 0.1480 | d_fake_loss: 0.3930 | d_total_loss: 0.5410 |  g_loss: 0.5583
Iteration [ 1330/10000] | d_real_loss: 0.4725 | d_fake_loss: 0.0753 | d_total_loss: 0.5477 |  g_loss: 0.2490
Iteration [ 1340/10000] | d_real_loss: 0.1972 | d_fake_loss: 0.2167 | d_total_loss: 0.4139 |  g_loss: 0.5164
Iteration [ 1350/10000] | d_real_loss: 0.1059 | d_fake_loss: 0.3292 | d_total_loss: 0.4350 |  g_loss: 0.9989
Iteration [ 1360/10000] | d_real_loss: 0.3232 | d_fake_loss: 0.1058 | d_total_loss: 0.4290 |  g_loss: 0.3694
Iteration [ 1370/10000] | d_real_loss: 0.1982 | d_fake_loss: 0.1169 | d_total_loss: 0.3151 |  g_loss: 0.4809
Iteration [ 1380/10000] | d_real_loss: 0.1437 | d_fake_loss: 0.2706 | d_total_loss: 0.4142 |  g_loss: 0.5464
Iteration [ 1390/10000] | d_real_loss: 0.1717 | d_fake_loss: 0.2168 | d_total_loss: 0.3886 |  g_loss: 0.5861
Iteration [ 1400/10000] | d_real_loss: 0.2594 | d_fake_loss: 0.1080 | d_total_loss: 0.3674 |  g_loss: 0.3119
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001400.png
Iteration [ 1410/10000] | d_real_loss: 0.1112 | d_fake_loss: 0.4718 | d_total_loss: 0.5830 |  g_loss: 0.6271
Iteration [ 1420/10000] | d_real_loss: 0.1501 | d_fake_loss: 0.3024 | d_total_loss: 0.4525 |  g_loss: 0.4491
Iteration [ 1430/10000] | d_real_loss: 0.2681 | d_fake_loss: 0.1381 | d_total_loss: 0.4062 |  g_loss: 0.3999
Iteration [ 1440/10000] | d_real_loss: 0.4758 | d_fake_loss: 0.0402 | d_total_loss: 0.5161 |  g_loss: 0.2048
Iteration [ 1450/10000] | d_real_loss: 0.1328 | d_fake_loss: 0.2493 | d_total_loss: 0.3821 |  g_loss: 0.6848
Iteration [ 1460/10000] | d_real_loss: 0.1880 | d_fake_loss: 0.2077 | d_total_loss: 0.3957 |  g_loss: 0.5406
Iteration [ 1470/10000] | d_real_loss: 0.3124 | d_fake_loss: 0.1172 | d_total_loss: 0.4296 |  g_loss: 0.2282
Iteration [ 1480/10000] | d_real_loss: 0.3682 | d_fake_loss: 0.0713 | d_total_loss: 0.4396 |  g_loss: 0.2319
Iteration [ 1490/10000] | d_real_loss: 0.2027 | d_fake_loss: 0.2417 | d_total_loss: 0.4443 |  g_loss: 0.6522
Iteration [ 1500/10000] | d_real_loss: 0.1594 | d_fake_loss: 0.2047 | d_total_loss: 0.3641 |  g_loss: 0.4893
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001500.png
Iteration [ 1510/10000] | d_real_loss: 0.1873 | d_fake_loss: 0.2072 | d_total_loss: 0.3946 |  g_loss: 0.6597
Iteration [ 1520/10000] | d_real_loss: 0.1662 | d_fake_loss: 0.1764 | d_total_loss: 0.3426 |  g_loss: 0.6567
Iteration [ 1530/10000] | d_real_loss: 0.1331 | d_fake_loss: 0.2351 | d_total_loss: 0.3683 |  g_loss: 0.6917
Iteration [ 1540/10000] | d_real_loss: 0.3226 | d_fake_loss: 0.0816 | d_total_loss: 0.4041 |  g_loss: 0.2314
Iteration [ 1550/10000] | d_real_loss: 0.0669 | d_fake_loss: 0.4022 | d_total_loss: 0.4691 |  g_loss: 0.9032
Iteration [ 1560/10000] | d_real_loss: 0.4160 | d_fake_loss: 0.0567 | d_total_loss: 0.4727 |  g_loss: 0.3051
Iteration [ 1570/10000] | d_real_loss: 0.2179 | d_fake_loss: 0.1454 | d_total_loss: 0.3633 |  g_loss: 0.3530
Iteration [ 1580/10000] | d_real_loss: 0.1678 | d_fake_loss: 0.2193 | d_total_loss: 0.3871 |  g_loss: 0.4775
Iteration [ 1590/10000] | d_real_loss: 0.3048 | d_fake_loss: 0.1338 | d_total_loss: 0.4386 |  g_loss: 0.3583
Iteration [ 1600/10000] | d_real_loss: 0.1581 | d_fake_loss: 0.2763 | d_total_loss: 0.4345 |  g_loss: 0.5387
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001600.png
Iteration [ 1610/10000] | d_real_loss: 0.0583 | d_fake_loss: 0.5395 | d_total_loss: 0.5978 |  g_loss: 0.5838
Iteration [ 1620/10000] | d_real_loss: 0.1761 | d_fake_loss: 0.1745 | d_total_loss: 0.3507 |  g_loss: 0.4819
Iteration [ 1630/10000] | d_real_loss: 0.3918 | d_fake_loss: 0.0915 | d_total_loss: 0.4833 |  g_loss: 0.2410
Iteration [ 1640/10000] | d_real_loss: 0.2582 | d_fake_loss: 0.1159 | d_total_loss: 0.3741 |  g_loss: 0.5097
Iteration [ 1650/10000] | d_real_loss: 0.1902 | d_fake_loss: 0.1595 | d_total_loss: 0.3498 |  g_loss: 0.4732
Iteration [ 1660/10000] | d_real_loss: 0.2549 | d_fake_loss: 0.1411 | d_total_loss: 0.3960 |  g_loss: 0.4884
Iteration [ 1670/10000] | d_real_loss: 0.1127 | d_fake_loss: 0.2801 | d_total_loss: 0.3929 |  g_loss: 0.7139
Iteration [ 1680/10000] | d_real_loss: 0.1035 | d_fake_loss: 0.1987 | d_total_loss: 0.3022 |  g_loss: 0.7155
Iteration [ 1690/10000] | d_real_loss: 0.1949 | d_fake_loss: 0.1908 | d_total_loss: 0.3856 |  g_loss: 0.5708
Iteration [ 1700/10000] | d_real_loss: 0.2270 | d_fake_loss: 0.1285 | d_total_loss: 0.3554 |  g_loss: 0.4483
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001700.png
Iteration [ 1710/10000] | d_real_loss: 0.2194 | d_fake_loss: 0.1341 | d_total_loss: 0.3535 |  g_loss: 0.4193
Iteration [ 1720/10000] | d_real_loss: 0.1310 | d_fake_loss: 0.1978 | d_total_loss: 0.3288 |  g_loss: 0.5721
Iteration [ 1730/10000] | d_real_loss: 0.0610 | d_fake_loss: 0.3919 | d_total_loss: 0.4529 |  g_loss: 0.7571
Iteration [ 1740/10000] | d_real_loss: 0.0840 | d_fake_loss: 0.2646 | d_total_loss: 0.3486 |  g_loss: 0.8094
Iteration [ 1750/10000] | d_real_loss: 0.2513 | d_fake_loss: 0.1311 | d_total_loss: 0.3824 |  g_loss: 0.5069
Iteration [ 1760/10000] | d_real_loss: 0.3304 | d_fake_loss: 0.0637 | d_total_loss: 0.3941 |  g_loss: 0.3786
Iteration [ 1770/10000] | d_real_loss: 0.1956 | d_fake_loss: 0.1073 | d_total_loss: 0.3029 |  g_loss: 0.4825
Iteration [ 1780/10000] | d_real_loss: 0.2528 | d_fake_loss: 0.1159 | d_total_loss: 0.3687 |  g_loss: 0.4031
Iteration [ 1790/10000] | d_real_loss: 0.0639 | d_fake_loss: 0.4214 | d_total_loss: 0.4853 |  g_loss: 0.8608
Iteration [ 1800/10000] | d_real_loss: 0.1933 | d_fake_loss: 0.2025 | d_total_loss: 0.3958 |  g_loss: 0.4972
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001800.png
Iteration [ 1810/10000] | d_real_loss: 0.2611 | d_fake_loss: 0.1344 | d_total_loss: 0.3955 |  g_loss: 0.4197
Iteration [ 1820/10000] | d_real_loss: 0.2659 | d_fake_loss: 0.0576 | d_total_loss: 0.3236 |  g_loss: 0.2571
Iteration [ 1830/10000] | d_real_loss: 0.2422 | d_fake_loss: 0.1445 | d_total_loss: 0.3867 |  g_loss: 0.4183
Iteration [ 1840/10000] | d_real_loss: 0.2757 | d_fake_loss: 0.1215 | d_total_loss: 0.3972 |  g_loss: 0.3035
Iteration [ 1850/10000] | d_real_loss: 0.2819 | d_fake_loss: 0.1224 | d_total_loss: 0.4043 |  g_loss: 0.3258
Iteration [ 1860/10000] | d_real_loss: 0.2370 | d_fake_loss: 0.1047 | d_total_loss: 0.3417 |  g_loss: 0.5552
Iteration [ 1870/10000] | d_real_loss: 0.2347 | d_fake_loss: 0.0944 | d_total_loss: 0.3291 |  g_loss: 0.5418
Iteration [ 1880/10000] | d_real_loss: 0.0945 | d_fake_loss: 0.2532 | d_total_loss: 0.3477 |  g_loss: 0.7906
Iteration [ 1890/10000] | d_real_loss: 0.0891 | d_fake_loss: 0.2913 | d_total_loss: 0.3804 |  g_loss: 0.8788
Iteration [ 1900/10000] | d_real_loss: 0.1064 | d_fake_loss: 0.2620 | d_total_loss: 0.3684 |  g_loss: 0.7391
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-001900.png
Iteration [ 1910/10000] | d_real_loss: 0.0934 | d_fake_loss: 0.5197 | d_total_loss: 0.6131 |  g_loss: 1.0463
Iteration [ 1920/10000] | d_real_loss: 0.2580 | d_fake_loss: 0.1254 | d_total_loss: 0.3833 |  g_loss: 0.4153
Iteration [ 1930/10000] | d_real_loss: 0.2210 | d_fake_loss: 0.1286 | d_total_loss: 0.3496 |  g_loss: 0.3939
Iteration [ 1940/10000] | d_real_loss: 0.3254 | d_fake_loss: 0.0868 | d_total_loss: 0.4121 |  g_loss: 0.2636
Iteration [ 1950/10000] | d_real_loss: 0.2946 | d_fake_loss: 0.0921 | d_total_loss: 0.3867 |  g_loss: 0.3333
Iteration [ 1960/10000] | d_real_loss: 0.2801 | d_fake_loss: 0.0848 | d_total_loss: 0.3648 |  g_loss: 0.2666
Iteration [ 1970/10000] | d_real_loss: 0.3972 | d_fake_loss: 0.0502 | d_total_loss: 0.4475 |  g_loss: 0.2649
Iteration [ 1980/10000] | d_real_loss: 0.1508 | d_fake_loss: 0.1972 | d_total_loss: 0.3480 |  g_loss: 0.6097
Iteration [ 1990/10000] | d_real_loss: 0.2276 | d_fake_loss: 0.1586 | d_total_loss: 0.3862 |  g_loss: 0.3785
Iteration [ 2000/10000] | d_real_loss: 0.1292 | d_fake_loss: 0.2584 | d_total_loss: 0.3876 |  g_loss: 0.5397
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-002000.png
Iteration [ 2010/10000] | d_real_loss: 0.2080 | d_fake_loss: 0.1879 | d_total_loss: 0.3958 |  g_loss: 0.4798
Iteration [ 2020/10000] | d_real_loss: 0.2081 | d_fake_loss: 0.1748 | d_total_loss: 0.3830 |  g_loss: 0.4635
Iteration [ 2030/10000] | d_real_loss: 0.1702 | d_fake_loss: 0.2232 | d_total_loss: 0.3934 |  g_loss: 0.5360
Iteration [ 2040/10000] | d_real_loss: 0.1642 | d_fake_loss: 0.2570 | d_total_loss: 0.4212 |  g_loss: 0.6395
Iteration [ 2050/10000] | d_real_loss: 0.3302 | d_fake_loss: 0.0664 | d_total_loss: 0.3965 |  g_loss: 0.2807
Iteration [ 2060/10000] | d_real_loss: 0.0569 | d_fake_loss: 0.4076 | d_total_loss: 0.4645 |  g_loss: 1.1707
Iteration [ 2070/10000] | d_real_loss: 0.0952 | d_fake_loss: 0.3203 | d_total_loss: 0.4154 |  g_loss: 0.6738
Iteration [ 2080/10000] | d_real_loss: 0.1371 | d_fake_loss: 0.2322 | d_total_loss: 0.3693 |  g_loss: 0.5560
Iteration [ 2090/10000] | d_real_loss: 0.2667 | d_fake_loss: 0.1278 | d_total_loss: 0.3945 |  g_loss: 0.3731
Iteration [ 2100/10000] | d_real_loss: 0.2252 | d_fake_loss: 0.1028 | d_total_loss: 0.3280 |  g_loss: 0.4439
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-002100.png
Iteration [ 2110/10000] | d_real_loss: 0.0809 | d_fake_loss: 0.3536 | d_total_loss: 0.4346 |  g_loss: 1.3088
Iteration [ 2120/10000] | d_real_loss: 0.4504 | d_fake_loss: 0.0439 | d_total_loss: 0.4942 |  g_loss: 0.1421
Iteration [ 2130/10000] | d_real_loss: 0.1394 | d_fake_loss: 0.1884 | d_total_loss: 0.3278 |  g_loss: 0.6355
Iteration [ 2140/10000] | d_real_loss: 0.2616 | d_fake_loss: 0.1078 | d_total_loss: 0.3694 |  g_loss: 0.5878
Iteration [ 2150/10000] | d_real_loss: 0.3096 | d_fake_loss: 0.0832 | d_total_loss: 0.3928 |  g_loss: 0.3716
Iteration [ 2160/10000] | d_real_loss: 0.1386 | d_fake_loss: 0.2047 | d_total_loss: 0.3432 |  g_loss: 0.5436
Iteration [ 2170/10000] | d_real_loss: 0.0594 | d_fake_loss: 0.3893 | d_total_loss: 0.4487 |  g_loss: 0.9461
Iteration [ 2180/10000] | d_real_loss: 0.1803 | d_fake_loss: 0.1649 | d_total_loss: 0.3451 |  g_loss: 0.6036
Iteration [ 2190/10000] | d_real_loss: 0.0708 | d_fake_loss: 0.3310 | d_total_loss: 0.4018 |  g_loss: 0.8972
Iteration [ 2200/10000] | d_real_loss: 0.4693 | d_fake_loss: 0.0311 | d_total_loss: 0.5004 |  g_loss: 0.1857
Saved output/cyclegan/.._10vanilla_instance_dc_cycle_naive/sample-002200.png
Iteration [ 2210/10000] | d_real_loss: 0.2855 | d_fake_loss: 0.1211 | d_total_loss: 0.4066 |  g_loss: 0.3487
Iteration [ 2220/10000] | d_real_loss: 0.2987 | d_fake_loss: 0.0594 | d_total_loss: 0.3581 |  g_loss: 0.4268
Iteration [ 2230/10000] | d_real_loss: 0.0726 | d_fake_loss: 0.2304 | d_total_loss: 0.3031 |  g_loss: 1.1826
Iteration [ 2240/10000] | d_real_loss: 0.1132 | d_fake_loss: 0.2797 | d_total_loss: 0.3928 |  g_loss: 0.7508
Iteration [ 2250/10000] | d_real_loss: 0.2118 | d_fake_loss: 0.1882 | d_total_loss: 0.4000 |  g_loss: 0.2943
Iteration [ 2260/10000] | d_real_loss: 0.2736 | d_fake_loss: 0.1497 | d_total_loss: 0.4233 |  g_loss: 0.3978
Traceback (most recent call last):
  File "/mnt/hw5/final_proj/16726-finalproject/style_GAN.py", line 462, in <module>
    os.system(cmd)
  File "/mnt/hw5/final_proj/16726-finalproject/style_GAN.py", line 376, in main
    # Create checkpoint and sample directories
  File "/mnt/hw5/final_proj/16726-finalproject/style_GAN.py", line 279, in training_loop
    images = next(iter_X)
  File "/mnt/hw5/final_proj/16726-finalproject/utils.py", line 10, in to_var
    #     x = x.cuda()
KeyboardInterrupt
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
================================================================================
                                      Opts                                      
--------------------------------------------------------------------------------
                             image_size: 128                                    
                                   disc: dc                                     
                                    gen: cycle                                  
                                   iden: pretrained                             
                             g_conv_dim: 32                                     
                             d_conv_dim: 32                                     
                                   norm: instance                               
                              init_type: naive                                  
                            train_iters: 10000                                  
                             batch_size: 16                                     
                            num_workers: 2                                      
                                     lr: 0.0003                                 
                                  beta1: 0.5                                    
                                  beta2: 0.999                                  
                           lambda_cycle: 10                                     
                           lambda_style: 10                                     
                                      X: ..                                     
                                    ext: *.png                                  
                        data_preprocess: vanilla                                
                         checkpoint_dir: checkpoints_stylegan                   
                   iden_checkpoint_dir: checkpoints_pretrained_style_id         
                    sample_dir: output/cyclegan/.._10vanilla_instance_dc_cycle_naive
                               log_step: 10                                     
                           sample_every: 100                                    
                       checkpoint_every: 1000                                   
                                    gpu: 0                                      
================================================================================
Loaded 16 samples from ../labels
Loading Style Identifier from checkpoints_pretrained_style_id/style_identifier_iter49600.pkl
No checkpoint found, initializing new models.
                 G                
---------------------------------------
Generator(
  (conv1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (mlp): Sequential(
    (0): Linear(in_features=31, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
  )
  (resnet_block): Sequential(
    (0): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
    (1): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
    (2): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
  )
  (up_conv1): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU()
  )
  (up_conv2): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU()
  )
  (up_conv3): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Tanh()
  )
)
---------------------------------------
                 D                
---------------------------------------
Discriminator(
  (conv1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv4): Sequential(
    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv5): Sequential(
    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))
  )
)
---------------------------------------
                  style_identifier                  
---------------------------------------
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=31, bias=True)
)
---------------------------------------
tensor([[0.0060, 0.0031, 0.0545, 0.0011, 0.0043, 0.0018, 0.0006, 0.0022, 0.0024,
         0.0036, 0.0177, 0.0004, 0.0141, 0.0088, 0.0211, 0.0019, 0.0091, 0.0027,
         0.0005, 0.0022, 0.0010, 0.0024, 0.0258, 0.0013, 0.0373, 0.0009, 0.0008,
         0.0031, 0.0172, 0.0425, 0.0105]], grad_fn=<SigmoidBackward0>) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])
Traceback (most recent call last):
  File "/mnt/hw5/final_proj/16726-finalproject/style_GAN.py", line 467, in <module>
    main(opts)
  File "/mnt/hw5/final_proj/16726-finalproject/style_GAN.py", line 381, in main
    training_loop(dataloader_X, opts)
  File "/mnt/hw5/final_proj/16726-finalproject/style_GAN.py", line 314, in training_loop
    fake_images = G(images_expanded, new_labels)
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/hw5/final_proj/16726-finalproject/models.py", line 138, in forward
    x = self.conv2(x) 
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 74, in forward
    return self._apply_instance_norm(input)
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 34, in _apply_instance_norm
    return F.instance_norm(
  File "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py", line 2495, in instance_norm
    return torch.instance_norm(
KeyboardInterrupt
