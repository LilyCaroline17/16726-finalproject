/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/ubuntu/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
================================================================================
                                      Opts                                      
--------------------------------------------------------------------------------
                             image_size: 128                                    
                                   disc: dc                                     
                                    gen: cycle                                  
                                   iden: pretrained                             
                             g_conv_dim: 32                                     
                             d_conv_dim: 32                                     
                                   norm: instance                               
                              init_type: naive                                  
                            train_iters: 10000                                  
                             batch_size: 16                                     
                            num_workers: 2                                      
                                     lr: 0.0003                                 
                                  beta1: 0.5                                    
                                  beta2: 0.999                                  
                           lambda_cycle: 3                                      
                           lambda_style: 10                                     
                                      X: ..                                     
                                    ext: *.png                                  
                        data_preprocess: vanilla                                
                         checkpoint_dir: checkpoints_stylegan                   
                   iden_checkpoint_dir: checkpoints_pretrained_style_id         
                    sample_dir: output/cyclegan/.._3pretrained_instance_dc_cycle_naive
                               log_step: 10                                     
                           sample_every: 500                                    
                       checkpoint_every: 1000                                   
                                    gpu: 0                                      
================================================================================
Loaded 97724 samples from ../labels
No checkpoint found, initializing new models.
Models moved to GPU.
Loading Style Identifier from checkpoints_pretrained_style_id/style_identifier_iter.pkl
                 G                
---------------------------------------
Generator(
  (conv1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (mlp): Sequential(
    (0): Linear(in_features=31, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
  )
  (resnet_block): Sequential(
    (0): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
    (1): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
    (2): ResnetBlock(
      (conv_layer): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU()
      )
    )
  )
  (up_conv1): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU()
  )
  (up_conv2): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU()
  )
  (up_conv3): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Tanh()
  )
)
---------------------------------------
                 D                
---------------------------------------
Discriminator(
  (conv1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv4): Sequential(
    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU()
  )
  (conv5): Sequential(
    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))
  )
)
---------------------------------------
                  style_identifier                  
---------------------------------------
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=31, bias=True)
)
---------------------------------------
Iteration [   10/10000] | d_real_loss: 0.2341 | d_fake_loss: 0.2604 | d_total_loss: 0.4945 |  g_loss: 1.2902
Iteration [   20/10000] | d_real_loss: 0.3413 | d_fake_loss: 0.2049 | d_total_loss: 0.5463 |  g_loss: 0.4812
Iteration [   30/10000] | d_real_loss: 0.1844 | d_fake_loss: 0.2375 | d_total_loss: 0.4219 |  g_loss: 0.7058
Iteration [   40/10000] | d_real_loss: 0.2733 | d_fake_loss: 0.2879 | d_total_loss: 0.5612 |  g_loss: 0.4582
Iteration [   50/10000] | d_real_loss: 0.4196 | d_fake_loss: 0.1445 | d_total_loss: 0.5641 |  g_loss: 0.4428
Iteration [   60/10000] | d_real_loss: 0.1812 | d_fake_loss: 0.2576 | d_total_loss: 0.4388 |  g_loss: 0.5055
Iteration [   70/10000] | d_real_loss: 0.2157 | d_fake_loss: 0.2610 | d_total_loss: 0.4767 |  g_loss: 0.5720
Iteration [   80/10000] | d_real_loss: 0.2710 | d_fake_loss: 0.1541 | d_total_loss: 0.4251 |  g_loss: 0.4210
Iteration [   90/10000] | d_real_loss: 0.1900 | d_fake_loss: 0.2559 | d_total_loss: 0.4459 |  g_loss: 0.5346
Iteration [  100/10000] | d_real_loss: 0.1440 | d_fake_loss: 0.3740 | d_total_loss: 0.5179 |  g_loss: 0.6586
Iteration [  110/10000] | d_real_loss: 0.1294 | d_fake_loss: 0.3268 | d_total_loss: 0.4562 |  g_loss: 0.6735
Iteration [  120/10000] | d_real_loss: 0.1254 | d_fake_loss: 0.3526 | d_total_loss: 0.4780 |  g_loss: 0.7693
Iteration [  130/10000] | d_real_loss: 0.1345 | d_fake_loss: 0.3073 | d_total_loss: 0.4418 |  g_loss: 0.6530
Iteration [  140/10000] | d_real_loss: 0.0809 | d_fake_loss: 0.4002 | d_total_loss: 0.4811 |  g_loss: 0.7789
Iteration [  150/10000] | d_real_loss: 0.2652 | d_fake_loss: 0.1271 | d_total_loss: 0.3923 |  g_loss: 0.4087
Iteration [  160/10000] | d_real_loss: 0.1602 | d_fake_loss: 0.2982 | d_total_loss: 0.4584 |  g_loss: 0.4147
Iteration [  170/10000] | d_real_loss: 0.2644 | d_fake_loss: 0.1370 | d_total_loss: 0.4015 |  g_loss: 0.3997
Iteration [  180/10000] | d_real_loss: 0.1070 | d_fake_loss: 0.3508 | d_total_loss: 0.4578 |  g_loss: 0.5970
Iteration [  190/10000] | d_real_loss: 0.1551 | d_fake_loss: 0.1359 | d_total_loss: 0.2911 |  g_loss: 0.5759
Iteration [  200/10000] | d_real_loss: 0.2298 | d_fake_loss: 0.1269 | d_total_loss: 0.3567 |  g_loss: 0.5147
Iteration [  210/10000] | d_real_loss: 0.1512 | d_fake_loss: 0.2020 | d_total_loss: 0.3532 |  g_loss: 0.6524
Iteration [  220/10000] | d_real_loss: 0.1650 | d_fake_loss: 0.2008 | d_total_loss: 0.3658 |  g_loss: 0.6921
Iteration [  230/10000] | d_real_loss: 0.2489 | d_fake_loss: 0.1512 | d_total_loss: 0.4001 |  g_loss: 0.4200
Iteration [  240/10000] | d_real_loss: 0.1372 | d_fake_loss: 0.2810 | d_total_loss: 0.4183 |  g_loss: 0.7627
Iteration [  250/10000] | d_real_loss: 0.3367 | d_fake_loss: 0.1043 | d_total_loss: 0.4410 |  g_loss: 0.3167
Iteration [  260/10000] | d_real_loss: 0.3545 | d_fake_loss: 0.0788 | d_total_loss: 0.4334 |  g_loss: 0.2608
Iteration [  270/10000] | d_real_loss: 0.1646 | d_fake_loss: 0.2611 | d_total_loss: 0.4257 |  g_loss: 0.6031
Iteration [  280/10000] | d_real_loss: 0.1342 | d_fake_loss: 0.3014 | d_total_loss: 0.4355 |  g_loss: 0.7008
Iteration [  290/10000] | d_real_loss: 0.2431 | d_fake_loss: 0.1537 | d_total_loss: 0.3967 |  g_loss: 0.3853
Iteration [  300/10000] | d_real_loss: 0.2819 | d_fake_loss: 0.1245 | d_total_loss: 0.4064 |  g_loss: 0.2874
Iteration [  310/10000] | d_real_loss: 0.2397 | d_fake_loss: 0.1627 | d_total_loss: 0.4024 |  g_loss: 0.4093
Iteration [  320/10000] | d_real_loss: 0.1021 | d_fake_loss: 0.3282 | d_total_loss: 0.4303 |  g_loss: 0.6752
Iteration [  330/10000] | d_real_loss: 0.2970 | d_fake_loss: 0.1245 | d_total_loss: 0.4214 |  g_loss: 0.3703
Iteration [  340/10000] | d_real_loss: 0.1847 | d_fake_loss: 0.2650 | d_total_loss: 0.4497 |  g_loss: 0.5269
Iteration [  350/10000] | d_real_loss: 0.1353 | d_fake_loss: 0.2910 | d_total_loss: 0.4263 |  g_loss: 0.6438
Iteration [  360/10000] | d_real_loss: 0.2333 | d_fake_loss: 0.2170 | d_total_loss: 0.4502 |  g_loss: 0.5164
Iteration [  370/10000] | d_real_loss: 0.0558 | d_fake_loss: 0.4468 | d_total_loss: 0.5026 |  g_loss: 0.8663
Iteration [  380/10000] | d_real_loss: 0.1844 | d_fake_loss: 0.1973 | d_total_loss: 0.3817 |  g_loss: 0.5435
Iteration [  390/10000] | d_real_loss: 0.1902 | d_fake_loss: 0.2063 | d_total_loss: 0.3965 |  g_loss: 0.6462
Iteration [  400/10000] | d_real_loss: 0.5607 | d_fake_loss: 0.0429 | d_total_loss: 0.6035 |  g_loss: 0.2440
Iteration [  410/10000] | d_real_loss: 0.1528 | d_fake_loss: 0.2700 | d_total_loss: 0.4227 |  g_loss: 0.4651
Iteration [  420/10000] | d_real_loss: 0.2332 | d_fake_loss: 0.1467 | d_total_loss: 0.3799 |  g_loss: 0.5085
Iteration [  430/10000] | d_real_loss: 0.3092 | d_fake_loss: 0.1152 | d_total_loss: 0.4244 |  g_loss: 0.3760
Iteration [  440/10000] | d_real_loss: 0.1774 | d_fake_loss: 0.1957 | d_total_loss: 0.3731 |  g_loss: 0.4340
Iteration [  450/10000] | d_real_loss: 0.3135 | d_fake_loss: 0.1253 | d_total_loss: 0.4388 |  g_loss: 0.5317
Iteration [  460/10000] | d_real_loss: 0.4321 | d_fake_loss: 0.0530 | d_total_loss: 0.4851 |  g_loss: 0.1963
Iteration [  470/10000] | d_real_loss: 0.0903 | d_fake_loss: 0.3097 | d_total_loss: 0.4000 |  g_loss: 0.5309
Iteration [  480/10000] | d_real_loss: 0.1949 | d_fake_loss: 0.3787 | d_total_loss: 0.5735 |  g_loss: 0.7372
Iteration [  490/10000] | d_real_loss: 0.2680 | d_fake_loss: 0.1285 | d_total_loss: 0.3965 |  g_loss: 0.5061
Iteration [  500/10000] | d_real_loss: 0.1463 | d_fake_loss: 0.2596 | d_total_loss: 0.4059 |  g_loss: 0.5869
Saved output/cyclegan/.._3pretrained_instance_dc_cycle_naive/sample-000500.png
Iteration [  510/10000] | d_real_loss: 0.3210 | d_fake_loss: 0.1170 | d_total_loss: 0.4379 |  g_loss: 0.3118
Iteration [  520/10000] | d_real_loss: 0.2604 | d_fake_loss: 0.1147 | d_total_loss: 0.3751 |  g_loss: 0.3251
Iteration [  530/10000] | d_real_loss: 0.1391 | d_fake_loss: 0.2917 | d_total_loss: 0.4308 |  g_loss: 0.7443
Iteration [  540/10000] | d_real_loss: 0.1627 | d_fake_loss: 0.1982 | d_total_loss: 0.3609 |  g_loss: 0.5063
Iteration [  550/10000] | d_real_loss: 0.7335 | d_fake_loss: 0.0321 | d_total_loss: 0.7657 |  g_loss: 0.1435
Iteration [  560/10000] | d_real_loss: 0.1989 | d_fake_loss: 0.2039 | d_total_loss: 0.4028 |  g_loss: 0.4512
Iteration [  570/10000] | d_real_loss: 0.2867 | d_fake_loss: 0.1579 | d_total_loss: 0.4446 |  g_loss: 0.2226
Iteration [  580/10000] | d_real_loss: 0.1350 | d_fake_loss: 0.2435 | d_total_loss: 0.3786 |  g_loss: 0.5416
Iteration [  590/10000] | d_real_loss: 0.2101 | d_fake_loss: 0.1182 | d_total_loss: 0.3283 |  g_loss: 0.3965
Iteration [  600/10000] | d_real_loss: 0.2984 | d_fake_loss: 0.1246 | d_total_loss: 0.4230 |  g_loss: 0.4570
Iteration [  610/10000] | d_real_loss: 0.1662 | d_fake_loss: 0.2066 | d_total_loss: 0.3728 |  g_loss: 0.4939
Iteration [  620/10000] | d_real_loss: 0.1046 | d_fake_loss: 0.3696 | d_total_loss: 0.4742 |  g_loss: 0.7605
Iteration [  630/10000] | d_real_loss: 0.1022 | d_fake_loss: 0.2557 | d_total_loss: 0.3579 |  g_loss: 0.7284
Iteration [  640/10000] | d_real_loss: 0.2323 | d_fake_loss: 0.1286 | d_total_loss: 0.3609 |  g_loss: 0.6241
Iteration [  650/10000] | d_real_loss: 0.1939 | d_fake_loss: 0.2186 | d_total_loss: 0.4124 |  g_loss: 0.5484
Iteration [  660/10000] | d_real_loss: 0.0887 | d_fake_loss: 0.3507 | d_total_loss: 0.4394 |  g_loss: 0.9592
Iteration [  670/10000] | d_real_loss: 0.1639 | d_fake_loss: 0.2288 | d_total_loss: 0.3927 |  g_loss: 0.7823
Iteration [  680/10000] | d_real_loss: 0.3333 | d_fake_loss: 0.0811 | d_total_loss: 0.4144 |  g_loss: 0.4085
Iteration [  690/10000] | d_real_loss: 0.2156 | d_fake_loss: 0.1478 | d_total_loss: 0.3634 |  g_loss: 0.4887
Iteration [  700/10000] | d_real_loss: 0.0821 | d_fake_loss: 0.3303 | d_total_loss: 0.4124 |  g_loss: 0.6490
Iteration [  710/10000] | d_real_loss: 0.1680 | d_fake_loss: 0.1668 | d_total_loss: 0.3348 |  g_loss: 0.5467
Iteration [  720/10000] | d_real_loss: 0.1620 | d_fake_loss: 0.1797 | d_total_loss: 0.3416 |  g_loss: 0.5263
Iteration [  730/10000] | d_real_loss: 0.4350 | d_fake_loss: 0.0791 | d_total_loss: 0.5141 |  g_loss: 0.1896
Iteration [  740/10000] | d_real_loss: 0.1007 | d_fake_loss: 0.2793 | d_total_loss: 0.3800 |  g_loss: 0.7167
